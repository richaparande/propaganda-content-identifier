{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, out_dim, dp_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, input_dim*2)\n",
    "        self.output_layer = nn.Linear(input_dim*2, out_dim)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "       \n",
    "    def forward(self, x_in):\n",
    "        z1 = self.dropout(x_in) # output of the input layer, after dropout\n",
    "        z2 = self.relu(self.hidden_layer(z1)) # output of the hidden layer\n",
    "        logits = self.output_layer(z2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "path_of_downloaded_files = \"/users/richa/glove.6B/glove.6B.300d.txt\"\n",
    "glove_file = datapath(path_of_downloaded_files)\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def vectorize_sent(word_vectors, sent, oov_vec):\n",
    "    word_vecs = []\n",
    "    for token in word_tokenize(sent): \n",
    "        if token not in word_vectors: \n",
    "            word_vecs.append(oov_vec)\n",
    "        else:\n",
    "            word_vecs.append(word_vectors[token].astype('float64'))\n",
    "    return np.mean(word_vecs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct trained model from pickle\n",
    "\n",
    "import pickle\n",
    "def reconstruct_model(pickle_path):\n",
    "    saved_model_dic = pickle.load(open(pickle_path,\"rb\"))\n",
    "    input_dim = saved_model_dic['input_dim']\n",
    "    dp_rate = saved_model_dic['dropout_rate']\n",
    "    output_dim = 2\n",
    "    model = MLP(input_dim, output_dim, dp_rate)\n",
    "    saved_weights = saved_model_dic['neural_weights']\n",
    "    n_epochs = saved_model_dic['n_epochs']\n",
    "    batch_size = saved_model_dic['batch_size']\n",
    "    lr = saved_model_dic['lr']\n",
    "    model.load_state_dict(saved_weights, batch_size)\n",
    "    oov_vec = saved_model_dic['oov_vector']\n",
    "    \n",
    "    return model, oov_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the reconstructed model to make predictions on the test data\n",
    "\n",
    "def test_trained_model(model, oov_vec, test_text):\n",
    "    test_vecs = [vectorize_sent(word_vectors, ss, oov_vec ) for ss in test_text]\n",
    "    test_vecs_tensor = torch.tensor(test_vecs, dtype=torch.float)\n",
    "    test_prediction = model(test_vecs_tensor)\n",
    "    pred_labels = [np.argmax(tp.detach().numpy()) for tp in test_prediction]\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample test data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "test_data = pd.read_table('coursework2_train.tsv')\n",
    "test_text = test_data['sentence_text'].tolist()[-2000:]\n",
    "test_raw_labels = test_data['label'].tolist()[-2000:]\n",
    "label_dic = {'non-propaganda':0, 'propaganda':1} \n",
    "test_labels = [label_dic[rl] for rl in test_raw_labels]\n",
    "\n",
    "print('test data size:', len(test_labels))\n",
    "\n",
    "# reconstruct model and make predictions\n",
    "\n",
    "model, oov_vec = reconstruct_model('trained_model.pickle')\n",
    "test_pred = test_trained_model(model, oov_vec, test_text)\n",
    "\n",
    "# test model\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score\n",
    "pre, rec, f1, _ = precision_recall_fscore_support(test_labels, test_pred, average='macro')\n",
    "print('macro-F1 on test data:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
